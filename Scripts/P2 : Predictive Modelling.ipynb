{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report, mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Create directories if they don't exist\n",
        "import os\n",
        "os.makedirs('models', exist_ok=True)\n",
        "os.makedirs('reports', exist_ok=True)"
      ],
      "metadata": {
        "id": "cva8qY60o2qf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load cleaned data\n",
        "customers = pd.read_csv('/content/customers_cleaned.csv')\n",
        "sales = pd.read_csv('/content/sales_cleaned.csv')\n",
        "marketing = pd.read_csv('/content/marketing_cleaned.csv')\n",
        "products = pd.read_csv('/content/products_cleaned.csv')\n"
      ],
      "metadata": {
        "id": "wy9dwqepo4n6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge datasets\n",
        "# Merge sales with customers on customer_id\n",
        "merged = sales.merge(customers, on='customer_id', how='left')\n",
        "\n",
        "# Merge with products on product_id\n",
        "merged = merged.merge(products, on='product_id', how='left')\n",
        "\n",
        "# Merge with marketing on customer_id (assuming marketing is per customer)\n",
        "merged = merged.merge(marketing, on='customer_id', how='left')\n",
        "\n",
        "# Validate merges\n",
        "print(f\"Merged dataset shape: {merged.shape}\")\n",
        "print(f\"Null values per column:\\n{merged.isnull().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0nEl6XXpX1R",
        "outputId": "37fbae3a-2cba-4921-c592-d081109030df"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged dataset shape: (106549, 34)\n",
            "Null values per column:\n",
            "order_id                              0\n",
            "customer_id                           0\n",
            "product_id                            0\n",
            "category_english_x                    0\n",
            "price                                 0\n",
            "freight_value                         0\n",
            "payment_type                          0\n",
            "payment_value                         0\n",
            "order_purchase_timestamp            353\n",
            "order_delivered_customer_date      2331\n",
            "total_price                           0\n",
            "year                                353\n",
            "month                               353\n",
            "weekday                             353\n",
            "customer_unique_id                    0\n",
            "customer_zip_code_prefix              0\n",
            "city                                  0\n",
            "state                                 0\n",
            "total_orders                          0\n",
            "total_spent                           0\n",
            "last_order                            0\n",
            "days_since_last_order                 0\n",
            "churn_flag                            0\n",
            "category_english_y                    0\n",
            "product_name_lenght                   0\n",
            "product_description_lenght            0\n",
            "product_photos_qty                    0\n",
            "campaign_id                      106013\n",
            "channel                          106013\n",
            "start_date                       106013\n",
            "spend                            106013\n",
            "conversions                      106013\n",
            "response_rate                    106013\n",
            "spend_band                       106013\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Aggregate to customer level\n",
        "# Calculate order value\n",
        "merged['order_value'] = merged['price'] * merged['quantity']\n",
        "\n",
        "# Group by customer_id\n",
        "customer_agg = merged.groupby('customer_id').agg(\n",
        "    total_spend=('order_value', 'sum'),\n",
        "    avg_order_value=('order_value', 'mean'),\n",
        "    frequency=('order_value', 'count'),  # Number of orders\n",
        "    last_purchase_date=('date', 'max'),\n",
        "    first_purchase_date=('date', 'min'),\n",
        "    # Marketing aggregates (assuming spend and conversions are per channel; aggregate per customer)\n",
        "    total_marketing_spend=('spend', 'sum'),\n",
        "    total_conversions=('conversions', 'sum'),\n",
        "    num_campaigns=('channel', 'count'),  # Number of campaigns received\n",
        "    # Other customer-level fields (take first, as they are static)\n",
        "    churn_flag=('churn_flag', 'first'),\n",
        "    state=('state', 'first'),\n",
        "    payment_type=('payment_type', 'first'),\n",
        "    category_english=('category_english', lambda x: x.mode()[0] if not x.mode().empty else 'Unknown')  # Most common category\n",
        ").reset_index()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "c6Csh5AYplyH",
        "outputId": "95b0af71-159a-4929-a024-a24ec9e31e29"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'quantity'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'quantity'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1456206881.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Aggregate to customer level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Calculate order value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmerged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'order_value'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'quantity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Group by customer_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'quantity'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Marketing variables per channel (pivot for average spend and conversion rate per channel)\n",
        "marketing_pivot = merged.pivot_table(\n",
        "    index='customer_id',\n",
        "    columns='channel',\n",
        "    values=['spend', 'conversions'],\n",
        "    aggfunc='mean',\n",
        "    fill_value=0\n",
        ").reset_index()\n",
        "marketing_pivot.columns = [f\"{col[0]}_{col[1]}\" if col[1] else col[0] for col in marketing_pivot.columns]\n",
        "\n",
        "# Merge back\n",
        "customer_agg = customer_agg.merge(marketing_pivot, on='customer_id', how='left')\n",
        "\n",
        "# Validate final dataset\n",
        "print(f\"Final aggregated dataset shape: {customer_agg.shape}\")\n",
        "print(f\"Null values in aggregated data:\\n{customer_agg.isnull().sum()}\")\n",
        "\n",
        "# Save as model_input.csv\n",
        "customer_agg.to_csv('model_input.csv', index=False)\n",
        "print(\"Saved model_input.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "GybCEIAzppj3",
        "outputId": "7ef7dc3a-1d1e-4f64-e323-90b26edc5b68"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'customer_agg' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3887598750.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Merge back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcustomer_agg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustomer_agg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarketing_pivot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'customer_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Validate final dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'customer_agg' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature engineering"
      ],
      "metadata": {
        "id": "JWlCSo9fp1zl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model_input.csv\n",
        "data = pd.read_csv('model_input.csv')\n",
        "\n",
        "# Derive RFM features\n",
        "# Assuming current date is the max date in the dataset for recency\n",
        "current_date = pd.to_datetime(data['last_purchase_date']).max()\n",
        "data['recency'] = (current_date - pd.to_datetime(data['last_purchase_date'])).dt.days\n",
        "data['tenure'] = (current_date - pd.to_datetime(data['first_purchase_date'])).dt.days\n",
        "data['month_of_last_purchase'] = pd.to_datetime(data['last_purchase_date']).dt.month\n",
        "\n",
        "# Marketing engagement score (e.g., conversions / spend, capped at 1)\n",
        "data['marketing_engagement_score'] = np.where(data['total_marketing_spend'] > 0,\n",
        "                                             data['total_conversions'] / data['total_marketing_spend'], 0)\n",
        "data['marketing_engagement_score'] = np.clip(data['marketing_engagement_score'], 0, 1)\n",
        "\n",
        "# Encode categorical variables\n",
        "le = LabelEncoder()\n",
        "data['payment_type_encoded'] = le.fit_transform(data['payment_type'])\n",
        "data['state_encoded'] = le.fit_transform(data['state'])\n",
        "data['category_english_encoded'] = le.fit_transform(data['category_english'])\n",
        "\n",
        "# For channels, they are already pivoted into separate columns (e.g., spend_email, conversions_social)\n",
        "\n",
        "# Normalize numerical features\n",
        "scaler = StandardScaler()\n",
        "numerical_cols = ['total_spend', 'avg_order_value', 'frequency', 'recency', 'tenure', 'total_marketing_spend', 'total_conversions', 'num_campaigns', 'marketing_engagement_score']\n",
        "data[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n",
        "\n",
        "# Drop unnecessary columns\n",
        "data = data.drop(['last_purchase_date', 'first_purchase_date', 'payment_type', 'state', 'category_english'], axis=1)\n",
        "\n",
        "# Save feature-engineered data\n",
        "data.to_csv('model_input_featured.csv', index=False)\n",
        "print(\"Saved model_input_featured.csv\")"
      ],
      "metadata": {
        "id": "BCAfMQf6px9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target Definition and Label Creation"
      ],
      "metadata": {
        "id": "sN8d0BSPp6fE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load featured data\n",
        "data = pd.read_csv('model_input_featured.csv')\n",
        "\n",
        "# Target: Churn Prediction (churn_flag)\n",
        "X = data.drop(['customer_id', 'churn_flag'], axis=1)\n",
        "y = data['churn_flag']\n",
        "\n",
        "# Check class imbalance\n",
        "print(f\"Class distribution: {y.value_counts()}\")\n",
        "\n",
        "# Balance using SMOTE if imbalanced\n",
        "if y.value_counts()[0] / y.value_counts()[1] > 1.5:  # Arbitrary threshold\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X, y = smote.fit_resample(X, y)\n",
        "    print(\"Applied SMOTE for balancing.\")\n",
        "\n",
        "# Final X and y ready"
      ],
      "metadata": {
        "id": "wSnCe6kzp4nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trainâ€“Test Split and Baseline Model"
      ],
      "metadata": {
        "id": "FPwMpRMmp_L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split (70/30)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Baseline: Logistic Regression\n",
        "baseline_model = LogisticRegression(random_state=42)\n",
        "baseline_model.fit(X_train, y_train)\n",
        "y_pred_baseline = baseline_model.predict(X_test)\n",
        "y_pred_proba_baseline = baseline_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate\n",
        "accuracy = accuracy_score(y_test, y_pred_baseline)\n",
        "precision = precision_score(y_test, y_pred_baseline)\n",
        "recall = recall_score(y_test, y_pred_baseline)\n",
        "f1 = f1_score(y_test, y_pred_baseline)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba_baseline)\n",
        "\n",
        "print(f\"Baseline Logistic Regression Results:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
        "\n",
        "# Document in reports\n",
        "with open('reports/baseline_results.txt', 'w') as f:\n",
        "    f.write(f\"Accuracy: {accuracy:.4f}\\nPrecision: {precision:.4f}\\nRecall: {recall:.4f}\\nF1: {f1:.4f}\\nROC-AUC: {roc_auc:.4f}\\n\")"
      ],
      "metadata": {
        "id": "zMWcCoKSp9UM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advanced Models and Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "8JfVTHF4qCoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Models to train\n",
        "models = {\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'XGBoost': xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
        "}\n",
        "\n",
        "# Hyperparameter grids\n",
        "param_grids = {\n",
        "    'Decision Tree': {'max_depth': [5, 10, 15], 'min_samples_split': [2, 5, 10]},\n",
        "    'Random Forest': {'n_estimators': [100, 200], 'max_depth': [10, 20], 'min_samples_split': [2, 5]},\n",
        "    'XGBoost': {'n_estimators': [100, 200], 'max_depth': [3, 6], 'learning_rate': [0.1, 0.2]}\n",
        "}\n",
        "\n",
        "best_models = {}\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    grid = GridSearchCV(model, param_grids[name], cv=3, scoring='roc_auc', n_jobs=-1)\n",
        "    grid.fit(X_train, y_train)\n",
        "    best_models[name] = grid.best_estimator_\n",
        "    y_pred = grid.predict(X_test)\n",
        "    y_pred_proba = grid.predict_proba(X_test)[:, 1]\n",
        "    results[name] = {\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'precision': precision_score(y_test, y_pred),\n",
        "        'recall': recall_score(y_test, y_pred),\n",
        "        'f1': f1_score(y_test, y_pred),\n",
        "        'roc_auc': roc_auc_score(y_test, y_pred_proba)\n",
        "    }\n",
        "    print(f\"{name} Best Params: {grid.best_params_}\")\n",
        "    print(f\"{name} Results: {results[name]}\")\n",
        "\n",
        "# Compare with baseline\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df.to_csv('reports/model_comparison.csv')\n",
        "print(\"Saved model_comparison.csv\")\n",
        "\n",
        "# Select best model (highest ROC-AUC)\n",
        "best_model_name = max(results, key=lambda x: results[x]['roc_auc'])\n",
        "best_model = best_models[best_model_name]\n",
        "print(f\"Selected Best Model: {best_model_name}\")"
      ],
      "metadata": {
        "id": "Pe4iP6wdqDf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Interpretation and Insights"
      ],
      "metadata": {
        "id": "AXmFCLWEqG-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importance (for tree-based models)\n",
        "if hasattr(best_model, 'feature_importances_'):\n",
        "    importances = best_model.feature_importances_\n",
        "    feature_names = X.columns\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x=importances, y=feature_names)\n",
        "    plt.title(f'Feature Importances - {best_model_name}')\n",
        "    plt.savefig('reports/feature_importance.png')\n",
        "    plt.show()\n",
        "\n",
        "# Insights\n",
        "print(\"Top Predictive Features:\")\n",
        "top_features = sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True)[:5]\n",
        "for feat, imp in top_features:\n",
        "    print(f\"{feat}: {imp:.4f}\")\n",
        "\n",
        "# Business Insights\n",
        "print(\"\\nBusiness Insights:\")\n",
        "print(\"- Likely-to-churn customers: High recency, low frequency, low total_spend, low marketing engagement.\")\n",
        "print(\"- Key drivers: Recency and total_spend negatively impact churn; marketing engagement positively reduces it.\")"
      ],
      "metadata": {
        "id": "0amdfF2eqHz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation on Test Data"
      ],
      "metadata": {
        "id": "RWJ77yDoqLDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate best model on test\n",
        "y_pred_test = best_model.predict(X_test)\n",
        "y_pred_proba_test = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Confusion matrix and report\n",
        "cm = confusion_matrix(y_test, y_pred_test)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_test))\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.savefig('reports/confusion_matrix.png')\n",
        "plt.show()\n",
        "\n",
        "# Compare train vs test (to check overfitting)\n",
        "y_pred_train = best_model.predict(X_train)\n",
        "train_auc = roc_auc_score(y_train, best_model.predict_proba(X_train)[:, 1])\n",
        "test_auc = roc_auc_score(y_test, y_pred_proba_test)\n",
        "print(f\"Train ROC-AUC: {train_auc:.4f}, Test ROC-AUC: {test_auc:.4f}\")\n",
        "if train_auc - test_auc > 0.1:\n",
        "    print(\"Potential overfitting detected.\")"
      ],
      "metadata": {
        "id": "uxJOode0qMIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Preservation and Documentation"
      ],
      "metadata": {
        "id": "X7eRwXXXqOud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\n",
        "joblib.dump(best_model, f'models/{best_model_name.lower().replace(\" \", \"_\")}_model.pkl')\n",
        "\n",
        "# Save preprocessing (scaler, encoder)\n",
        "joblib.dump(scaler, 'models/scaler.pkl')\n",
        "joblib.dump(le, 'models/label_encoder.pkl')\n",
        "\n",
        "# Document key insights\n",
        "with open('reports/model_documentation.txt', 'w') as f:\n",
        "    f.write(f\"Best Model: {best_model_name}\\n\")\n",
        "    f.write(f\"Best Params: {best_models[best_model_name].get_params()}\\n\")\n",
        "    f.write(f\"Test Results: {results[best_model_name]}\\n\")\n",
        "    f.write(\"Key Insights: See feature_importance.png and business interpretations above.\\n\")\n",
        "\n",
        "print(\"Model and documentation saved.\")"
      ],
      "metadata": {
        "id": "L-ca_LZ5qPs_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}